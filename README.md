MSTD* is a computational neuroscience project aimed at modeling motion and depth processing in the primate visual cortex.

It utilizes spiking neural networks (SNNs) based on the leaky integrate-and-fire neuron model.

Stimuli: The project includes artificial stimuli (moving bars in directions up, down, left, right) found in the "ds_models" directory and event camera recordings (hand-held camera moving in an office environment) in the "of_models" directory.

Learning: The project employs Spike-Timing-Dependent Plasticity (STDP) and backpropagation to achieve selectivity for motion directions and optic flow patterns.

Hardware: The models are capable of running on both CPU and GPU, with CUDA support available to enhance computational efficiency and performance.

MSTD stands for dorsal medial superior temporal.

